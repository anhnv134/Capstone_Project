"""##**Algorithm 6: Performance Tracking an d Post-Session Optimization**

**Goal:**

<div style="text-align: justify;">

Our goal here is after the session ends, evaluae key performance metrics (e.g., win rate, average Profit and Loss, maximum drawdown, Sharpe ratio).And after that we will use these insights to adjust parameters for future sessions.


</div>

**Inputs:**
- Trade logs of the day (e.g., entry prices, exit prices, timestamps, profit and loss per trade)
- Historical performance database for reference

**Pseudocode Steps:**

trades = load_today_trades()
metircs = calculate_performance_metrics(trades)

if metrics.drawdown > allowed_drawdown:
    # maybe we reduce position sizing or tighten filters next session

if metrics.win_rate < target_win_rate:
    # investigate false breakouts, consider adding a volume filter or adjust fibonacci ratio

log_metircs(metrics)

**Output:**

Updated parameters or notes for next session's improvement
"""

# Algorithm 6
# import necessary libraries

import os
import pandas as pd
import numpy as np
from datetime import datetime

#####################################
# CONFIGURE LOGGING
#####################################
LOG_DIR = "../Downloads/colab"

# Log file path
LOG_FILE = os.path.join(LOG_DIR, "Algo1_logfile.txt")


# ---------------------------
# LOG FUNCTION DEFINITIONS
# ---------------------------

def log_message(message, log_file=LOG_FILE):
    """
    Logs a message with a timestamp to the specified log file and prints it.

    """
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    full_message = f"[{timestamp}] {message}"
    print(full_message)
    try:
        with open(log_file, 'a') as f:
            f.write(full_message + "\n")
    except FileNotFoundError:
        print(f"ERROR: Log file directory does not exist: {os.path.dirname(log_file)}")
    except Exception as e:
        print(f"ERROR: Failed to write to log file. Exception: {e}")


###############################################################################
# PART A: LOADING TRADES & MANAGING POSITIONS
###############################################################################

def load_today_trades(csv_path):
    """
    Loads trades generated by Algorithm 4 or 5 from a CSV,
    Returns a DataFrame with columns typically including:
      'timestamp','Ticker','type','side','price','size','transaction_cost',....
    If not found or empty, returns an empty DataFrame.
    """
    if not os.path.exists(csv_path):
        log_message(f"[WARNING] No trades CSV found at {csv_path}")
        return pd.DataFrame()

    df_trades = pd.read_csv(csv_path)
    if df_trades.empty:
        log_message("[INFO] The trades CSV is empty. No trades to analyze.")
        return df_trades

    # Sort for clarity: (timestamp, Ticker) if columns exist
    if ('timestamp' in df_trades.columns) and ('Ticker' in df_trades.columns):
        df_trades.sort_values(['timestamp', 'Ticker'], inplace=True)
        df_trades.reset_index(drop=True, inplace=True)

    return df_trades


def position_pl_calculation(df_trades):
    """
    A more robust approach to match each 'ENTRY' with subsequent partial or full exits.
    - We track positions in a dictionary keyed by (Ticerk, side) => side E {'long','short'}.
    - Each position can be partially scaled in (multiple entries) or partially exited.
    - for scale-ins, we compute a new average cost basis for the position.
    - For partial exits, we do a pro-rata deduction of transaction costs from the open position.

    Returns:
      - A list (results) of dictionaries, each repersenting a realized exit action with fields:
          { 'Ticker', 'position_side', 'entry_price', 'exit_price',
            'close_qty', 'timestamp_exit', 'timestamp_entry', 'realized_pl' }
      - A dictionary (open_positions) of any positions that remain open at the end.

    NOTE: We unify all exit types ('EXIT','EXIT_EOD_FINAL','EXIT_STOP','EXIT_PROFIT','PARTIAL_EXIT')
          as legitimate closing actions. The only difference is how they appear in 'type' or 'side'.
    """

    # Key = (Ticker, 'long'/'short').
    # Value = {
    #   'avg_price'   : float (the average cost basis),
    #   'size'        : float (current open size/quantity),
    #   'accum_cost'  : float (sum of all transaction costs allocated to this position),
    #   'open_timestamp': str (when we first opened this position),
    # }
    open_positions = {}

    # This list will hold realized exit information. Each item is a dictionary with 'realized_pl',..etc.
    results = []

    # Here we define sets to recognize 'entry' vs. 'exit' actions:
    entry_types = {'ENTRY'}  # possibly could include 'SCALE_IN' if that existed
    exit_types = {
        'EXIT', 'EXIT_EOD_FINAL', 'EXIT_STOP',
        'EXIT_PROFIT', 'PARTIAL_EXIT'
    }

    for i, row in df_trades.iterrows():
        ttype = row.get('type', '')  # e.g. 'ENTRY', 'EXIT', 'EXIT_STOP', etc.
        side_action = row.get('side', '')  # e.g. 'BUY','SELL','BUY_STOP','SELL_STOP', etc.
        tkr = row.get('Ticker', 'UNK')
        price = row.get('price', 0.0)
        size = row.get('size', 0.0)
        cost = row.get('transaction_cost', 0.0)
        timestamp = row.get('timestamp', '')

        # 1) Determine if this row is an ENTRY OR EXIT
        if ttype in entry_types:
            # >>> ENTRY LOGIC <<<
            # WE interpret side='BUY' or side='BUY_STOP' => we are opening or adding to a 'long'
            # side='SELL' or side='SELL_STOP' => we are opening or adding to a 'short'

            if side_action.upper().startswith('BUY'):
                pos_key = (tkr, 'long')
            else:
                pos_key = (tkr, 'short')

            # If we already have an open positon on  (tkr, that side),
            # We do scale-in with a Weighted Average Price.
            if pos_key in open_positions:
                current = open_positions[pos_key]
                old_qty = current['size']
                old_avg = current['avg_price']  # old cost basis
                old_cost = current['accum_cost']

                new_qty = old_qty + size
                if new_qty <= 0:
                    # Edge case if size is negative or something.
                    # In normal usage, we don't expect that here. We'll skip gracefully.
                    continue

                # Weighted average price for scale-in:
                #   new_avg = (old_qty * old_avg + size * price) / (old_qty + size)
                new_avg = (old_qty * old_avg + size * price) / new_qty

                # Also add the new transaction cost ot accum_cost
                new_accum_cost = old_cost + cost

                # Update the dictionary
                open_positions[pos_key]['size'] = new_qty
                open_positions[pos_key]['avg_price'] = new_avg
                open_positions[pos_key]['accum_cost'] = new_accum_cost
                # open_timestamp remains the same if we want to track first open time

            else:
                # Create new position record
                open_positions[pos_key] = {
                    'avg_price': price,
                    'size': size,
                    'accum_cost': cost,
                    'open_timestamp': timestamp
                }

        elif ttype in exit_types:
            # >>> EXIT LOGIC <<<
            # We unify all exit types as closing actions.
            # If side_action is 'SELL' or 'SELL_STOP', that closes a 'long'
            # If side_action is 'BUY, or 'BUY_STOP', that closes a 'short'
            if side_action.upper().startswith('BUY'):
                pos_key = (tkr, 'short')
            else:
                pos_key = (tkr, 'long')

            # if no open position for that side, we skip
            if pos_key not in open_positions:
                continue

            current_pos = open_positions[pos_key]
            # partial or full exit, We'll close 'close_qty' = min(size, current_pos['size'])
            close_qty = min(size, current_pos['size'])

            # Realized P/L =
            #   if 'long': (exit_price - avg_price) * close_qty
            #   if 'short': (avg_price - exit_price) * close_qty
            if pos_key[1] == 'long':
                trade_pl = (price - current_pos['avg_price']) * close_qty
            else:  # short
                trade_pl = (current_pos['avg_price'] - price) * close_qty

            # 3) Transaction cost distribution:
            #    We do a pro-rata share of the postion's accumulated cost for partila exit.
            old_size = current_pos['size']
            old_cost = current_pos['accum_cost']
            fraction = close_qty / old_size

            # The portion of the previously accumulated cost we are 'using up' in this exit
            cost_allocation = old_cost * fraction
            # We also have the immediate exit cost = cost
            # net_pl = trade_pl - (cost_allocation + cost)
            net_pl = trade_pl - cost_allocation - cost

            exit_info = {
                'Ticker': tkr,
                'position_side': pos_key[1],
                'entry_price': current_pos['avg_price'],
                'exit_price': price,
                'close_qty': close_qty,
                'timestamp_exit': timestamp,
                'timestamp_entry': current_pos['open_timestamp'],
                'realized_pl': float(net_pl)
            }
            results.append(exit_info)

            # 4) Update or remove the open position
            remain = old_size - close_qty
            if remain <= 0:
                # fully closed
                del open_positions[pos_key]
            else:
                # partial remains
                # reduce size, reduce accum_cost by fraction
                open_positions[pos_key]['size'] = remain
                open_positions[pos_key]['accum_cost'] = old_cost - cost_allocation
                # avg_price doesn't change for the remiander
                # open_timestamp doesn't change either

        else:
            pass

    return results, open_positions


def finalize_pl_results(results):
    if not results:
        return []

    pl_list = [r['realized_pl'] for r in results]
    return pl_list


###############################################################################
# PART B: PERFORMANCE METRICS
###############################################################################
def compute_metrics_from_pl_list(pl_list):
    """
    Given a list of realized P/L values (floats),
    compute various performance metrics: net, win rate, avg P&L, max drawdown, sharpe ratio, etc.
    Returns a dictionary of metrics.
    """
    if len(pl_list) == 0:
        return {
            'net_pl': 0.0,
            'win_rate': 0.0,
            'avg_pl': 0.0,
            'max_drawdown': 0.0,
            'num_trades': 0,
            'sharpe_ratio': 0.0
        }

    net_pl = sum(pl_list)
    wins = [x for x in pl_list if x > 0]
    losses = [x for x in pl_list if x <= 0]
    num_trades = len(pl_list)
    win_rate = (len(wins) / num_trades) if num_trades else 0.0
    avg_pl = np.mean(pl_list)

    # Max drawdown via cumsum approach
    equity_curve = np.cumsum(pl_list)
    peak = equity_curve[0]
    dd = 0.0
    for val in equity_curve:
        if val > peak:
            peak = val
        drawdown = peak - val
        if drawdown > dd:
            dd = drawdown
    max_dd = dd

    # Sharpe ratio (naive approach)
    arr = np.array(pl_list)
    mean_ = arr.mean()
    std_ = arr.std(ddof=1)
    if std_ < 1e-9:
        sharpe = 0.0
    else:
        sharpe = mean_ / std_ * np.sqrt(num_trades)

    metrics = {
        'net_pl': float(net_pl),
        'win_rate': float(win_rate),
        'avg_pl': float(avg_pl),
        'max_drawdown': float(max_dd),
        'num_trades': num_trades,
        'sharpe_ratio': float(sharpe)
    }
    return metrics


def print_metrics(metrics):
    log_message("=== PERFORMANCE METRICS ===")
    log_message(f" Num Trades : {metrics['num_trades']}")
    log_message(f" Net P&L : {metrics['net_pl']:.2f}")
    log_message(f" Win Rate: {metrics['win_rate'] * 100:.1f}%")
    log_message(f" Avg P&L : {metrics['avg_pl']:.2f}")
    log_message(f" Max Drawdown : {metrics['max_drawdown']:.2f}")
    log_message(f" Sharpe Ratio : {metrics['sharpe_ratio']:.3f}")


###############################################################################
# PART D: LOGGING RESULTS (SAVING TO CSV)
###############################################################################
def save_metrics_to_csv(metrics, out_csv='Session_Performance_Log.csv'):
    columns = ["date", "num_trades", "net_pl", "win_rate", "avg_pl", "max_drawdown", "sharpe_ratio"]
    date_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    row_data = {
        "date": date_str,
        "num_trades": metrics['num_trades'],
        "net_pl": metrics['net_pl'],
        "win_rate": metrics['win_rate'],
        "avg_pl": metrics['avg_pl'],
        "max_drawdown": metrics['max_drawdown'],
        "sharpe_ratio": metrics['sharpe_ratio']
    }
    df_new = pd.DataFrame([row_data], columns=columns)
    if os.path.exists(out_csv):

        df_existing = pd.read_csv(out_csv)
        df_combined = pd.concat([df_existing, df_new], ignore_index=True)
        df_combined.to_csv(out_csv, index=False)
    else:
        df_new.to_csv(out_csv, index=False)

    log_message(f"[INFO] Metrics appended to: {out_csv}")


###############################################################################
# PART E: MAIN - ALGORITHM 6 (PRODUCTION-GRADE)
###############################################################################
def main():
    """
    Post-Session Steps:
      1. Load trades from an Algo output CSV (Algo4 or Algo5).
      2. Match positions & partial exits => realized P/L list.
      3. Compute advanced performance metrics (win rate, drawdown, sharpe, etc.).
      4. Print them + possibly log them to CSV for record-keeping.
      5. Suggest next-step optimizations if thresholds are violated.
    """

    # Suppose we evaluate trades from Algorithm 5
    trades_csv_path = "../colab/2021_selectedTickers/Algo5_Trades.csv"

    trades_csv_path = "../colab/2021_selectedTickers/Algo4_Trades.csv"

    log_message(f"[INFO] Loading trades from: {trades_csv_path}")
    df_trades = load_today_trades(trades_csv_path)
    if df_trades.empty:
        log_message("[INFO] No trades found. Exiting.")
        return

    # 1) Convert trades to realized P&L via position approach
    realized_exits, open_pos = position_pl_calculation(df_trades)
    if open_pos:
        log_message(f"[WARNING] Some positions remain open at session start: {open_pos}")

    # 2) Finalize P&L array
    pl_list = finalize_pl_results(realized_exits)

    # 3) Compute advanced metrics
    metrics = compute_metrics_from_pl_list(pl_list)

    # 4) Print them
    print_metrics(metrics)

    # 5) Log them to CSV for record
    perf_log_csv = "Session_Performance_Log.csv"
    save_metrics_to_csv(metrics, out_csv=perf_log_csv)


if __name__ == "__main__":
    main()